{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add below current directory to path\n",
    "# Notebook cannot import any code without this line !!!!\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, interact\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from tqdm import tqdm, trange # For progress bar\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models.CostModel import LogisticModel, RMSEModel\n",
    "\n",
    "from src.machinery.GradientDescent import ArtemisDescent, FL_VanillaSGD\n",
    "from src.machinery.GradientUpdateMethod import ArtemisUpdate\n",
    "from src.machinery.Parameters import *\n",
    "from src.machinery.PredefinedParameters import *\n",
    "\n",
    "from src.utils.ErrorPlotter import *\n",
    "from src.utils.Constants import *\n",
    "from src.utils.DataClustering import *\n",
    "from src.utils.DataPreparation import build_data_logistic, add_bias_term\n",
    "from src.utils.Utilities import pickle_loader, pickle_saver\n",
    "from src.utils.runner.RunnerUtilities import *\n",
    "from src.utils.runner.ResultsOfSeveralDescents import ResultsOfSeveralDescents\n",
    "\n",
    "filename = \"rcv1\"\n",
    "\n",
    "nb_devices_for_the_run = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cyanure as cyan\n",
    "import scipy.sparse\n",
    "#load rcv1 dataset about 1Gb, n=781265, p=47152\n",
    "data = np.load('/home/constantin/OneDrive/Documents/Etudes/Th√®se/dataset/rcv1/rcv1.npz',allow_pickle=True); Y_data=data['y']; X_data=data['X']\n",
    "X_data = scipy.sparse.csc_matrix(X_data.all()).T # n x p matrix, csr format\n",
    "#normalize the rows of X in-place, without performing any copy\n",
    "cyan.preprocess(X_data,normalize=True,columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points by devices:  2000\n",
      "There is 10 devices.\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n",
      "Number of points on this device: (2000, 47152)\n"
     ]
    }
   ],
   "source": [
    "#Transforming into torch.FloatTensor\n",
    "X_merged = X_data\n",
    "Y_merged = torch.tensor(Y_data, dtype=torch.float64)\n",
    "number_of_items = X_merged.shape[0]\n",
    "number_of_items_by_devices = number_of_items // nb_devices_for_the_run\n",
    "print(\"Number of points by devices: \", number_of_items_by_devices)\n",
    "\n",
    "X, Y = [], []\n",
    "for i in range(nb_devices_for_the_run):\n",
    "    X.append(scipy.sparse.csc_matrix(torch.tensor(\n",
    "        X_merged[number_of_items_by_devices * i:number_of_items_by_devices * (i+1)].A, dtype=torch.float64\n",
    "    )))\n",
    "    Y_temp = Y_merged[number_of_items_by_devices * i:number_of_items_by_devices * (i+1)]\n",
    "    Y.append(torch.stack([y[0] for y in Y_temp]))\n",
    "print(\"There is \" + str(len(X)) + \" devices.\")\n",
    "\n",
    "# Adding a columns of \"1\" to take into account a potential bias.\n",
    "#X = add_bias_term(X)\n",
    "dim_notebook = X[0].shape[1]\n",
    "for x in X:\n",
    "    print(\"Number of points on this device:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_notebook = X_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diplaying the ratio between state 1 and state -1.\n",
      "If data is iid, the ratio should be close to 0.5\n",
      "ratio of state 1 on this device:  0.461\n",
      "ratio of state 1 on this device:  0.4915\n",
      "ratio of state 1 on this device:  0.4465\n",
      "ratio of state 1 on this device:  0.472\n",
      "ratio of state 1 on this device:  0.47\n",
      "ratio of state 1 on this device:  0.481\n",
      "ratio of state 1 on this device:  0.4675\n",
      "ratio of state 1 on this device:  0.4625\n",
      "ratio of state 1 on this device:  0.4565\n",
      "ratio of state 1 on this device:  0.4755\n"
     ]
    }
   ],
   "source": [
    "# Checking that data is balanced over devices.\n",
    "print(\"Diplaying the ratio between state 1 and state -1.\")\n",
    "print(\"If data is iid, the ratio should be close to 0.5\")\n",
    "for y in Y:\n",
    "    print(\"ratio of state 1 on this device: \", abs((y == 1).sum().item() / abs(y).sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x47152 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 29 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Lipschitz constant ...\n",
      "Done.\n",
      "   it    |   obj   \n",
      "      20 | 4.4318e-01\n",
      "      40 | 3.6032e-01\n",
      "      60 | 3.1553e-01\n",
      "      80 | 2.8669e-01\n",
      "Gradient Descent: execution time=5.486 seconds\n",
      "Final loss :  0.2671044495199029\n",
      "\n",
      "CPU times: user 33.5 s, sys: 292 ms, total: 33.7 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gc\n",
    "gc.collect()\n",
    "obj_min_by_N = {}\n",
    "obj_min_by_N_descent = FL_VanillaSGD(Parameters(n_dimensions = dim_notebook, \n",
    "                                                     nb_devices=nb_devices_for_the_run,\n",
    "                                                     nb_epoch=5000, \n",
    "                                                     quantization_param=0,\n",
    "                                                     momentum = 0., \n",
    "                                                     verbose=True, \n",
    "                                                     cost_model=LogisticModel(),\n",
    "                                                     stochastic=False,\n",
    "                                                     bidirectional=False\n",
    "                                                    ))\n",
    "obj_min_by_N_descent.set_data(X,Y)\n",
    "obj_min_by_N_descent.run()\n",
    "obj_min_by_N = obj_min_by_N_descent.losses[-1]\n",
    "pickle_saver(obj_min_by_N, filename + \"-iid-obj_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels equal to 1:  868\n",
      "Failures: 42\n",
      "Percent of labels wrongly predicted to be state 1 for worker 0: 4.838709677419355%\n"
     ]
    }
   ],
   "source": [
    "x = X[0]\n",
    "w = obj_min_by_N_descent.model_params[-1]\n",
    "mul = torch.FloatTensor(x.dot(w))\n",
    "inf_middle = 0\n",
    "failure = 0\n",
    "for i in range(len(mul)):\n",
    "    if torch.sigmoid(mul[i]) > 0.5:\n",
    "        if Y[0][i] != 1:\n",
    "            failure +=1\n",
    "        inf_middle +=1\n",
    "print(\"Number of labels equal to 1: \", inf_middle)\n",
    "print(\"Failures:\", failure)\n",
    "print(\"Percent of labels wrongly predicted to be state 1 for worker 0: \" + str(failure/inf_middle * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_descent = {}\n",
    "X_number_of_bits = []\n",
    "for type_params in tqdm(KIND_COMPRESSION):\n",
    "    multiple_sg_descent = multiple_run_descent(type_params, X, Y, model = LogisticModel(), \n",
    "                                               use_averaging=True, nb_epoch=50)\n",
    "    all_descent[type_params.name()] = multiple_sg_descent\n",
    "res = ResultsOfSeveralDescents(all_descent, nb_devices_for_the_run)\n",
    "pickle_saver(res, filename + \"-iid-descent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pickle_loader(filename + \"-iid-obj_min\")\n",
    "res = pickle_loader(filename + \"-iid-descent\")\n",
    "\n",
    "plot_error_dist(res.get_loss(obj, averaged=True), res.names, res.nb_devices_for_the_run, \n",
    "                dim_notebook, all_error=res.get_std(obj, averaged=True), x_legend=\"Number of passes on data\\n(Avg, iid)\") \n",
    "plot_error_dist(res.get_loss(obj, averaged=True), res.names, res.nb_devices_for_the_run, dim_notebook, \n",
    "                x_points=res.X_number_of_bits, all_error=res.get_std(obj, averaged=True), \n",
    "                x_legend=\"Communicated bits (Avg, iid)\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pickle_loader(filename + \"-iid-obj_min\")\n",
    "res = pickle_loader(filename + \"-iid-descent\")\n",
    "\n",
    "plot_error_dist(res.get_loss(obj), res.names, res.nb_devices_for_the_run, dim_notebook,\n",
    "                x_legend=\"Number of passes on data (iid)\", all_error=res.get_std(obj)) \n",
    "plot_error_dist(res.get_loss(obj), res.names, res.nb_devices_for_the_run, dim_notebook, \n",
    "                x_points=res.X_number_of_bits, x_legend=\"Communicated bits (iid)\", all_error=res.get_std(obj)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
