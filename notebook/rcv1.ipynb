{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add below current directory to path\n",
    "# Notebook cannot import any code without this line !!!!\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, interact\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from tqdm import tqdm, trange # For progress bar\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models.CostModel import LogisticModel, RMSEModel, build_several_cost_model\n",
    "\n",
    "from src.machinery.GradientDescent import ArtemisDescent, FL_VanillaSGD\n",
    "from src.machinery.GradientUpdateMethod import ArtemisUpdate\n",
    "from src.machinery.Parameters import *\n",
    "from src.machinery.PredefinedParameters import *\n",
    "\n",
    "from src.utils.ErrorPlotter import *\n",
    "from src.utils.Constants import *\n",
    "from src.utils.DataClustering import *\n",
    "from src.utils.DataPreparation import build_data_logistic, add_bias_term\n",
    "from src.utils.Utilities import pickle_loader, pickle_saver\n",
    "from src.utils.runner.RunnerUtilities import *\n",
    "from src.utils.runner.ResultsOfSeveralDescents import ResultsOfSeveralDescents\n",
    "\n",
    "filename = \"rcv1\"\n",
    "\n",
    "nb_devices_for_the_run = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cyanure as cyan\n",
    "import scipy.sparse\n",
    "#load rcv1 dataset about 1Gb, n=781265, p=47152\n",
    "data = np.load('/home/constantin/OneDrive/Documents/Etudes/Thèse/dataset/rcv1/rcv1.npz',allow_pickle=True); Y_data=data['y']; X_data=data['X']\n",
    "X_data = scipy.sparse.csc_matrix(X_data.all()).T # n x p matrix, csr format\n",
    "#normalize the rows of X in-place, without performing any copy\n",
    "cyan.preprocess(X_data,normalize=True,columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points by devices:  2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 2 devices.\n",
      "Number of points on this device: (2500, 47152)\n",
      "Number of points on this device: (2500, 47152)\n",
      "CPU times: user 3.35 s, sys: 917 ms, total: 4.27 s\n",
      "Wall time: 2.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Transforming into torch.FloatTensor\n",
    "X_merged = X_data[:5000]\n",
    "Y_merged = torch.tensor(Y_data, dtype=torch.float64)[:5000]\n",
    "number_of_items = X_merged.shape[0]\n",
    "number_of_items_by_devices = number_of_items // nb_devices_for_the_run\n",
    "print(\"Number of points by devices: \", number_of_items_by_devices)\n",
    "\n",
    "X, Y = [], []\n",
    "for i in tqdm(range(nb_devices_for_the_run)):\n",
    "    X.append(scipy.sparse.csc_matrix(torch.tensor(\n",
    "        X_merged[number_of_items_by_devices * i:number_of_items_by_devices * (i+1)].A, dtype=torch.float64\n",
    "    )))\n",
    "    Y_temp = Y_merged[number_of_items_by_devices * i:number_of_items_by_devices * (i+1)]\n",
    "    Y.append(torch.stack([y[0] for y in Y_temp]))\n",
    "print(\"There is {0} devices.\".format(len(X)))\n",
    "\n",
    "# Adding a columns of \"1\" to take into account a potential bias.\n",
    "#X = add_bias_term(X)\n",
    "dim_notebook = X[0].shape[1]\n",
    "for x in X:\n",
    "    print(\"Number of points on this device: {0}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_notebook = X_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diplaying the ratio between state 1 and state -1.\n",
      "If data is iid, the ratio should be close to 0.5\n",
      "ratio of state 1 on this device: 0.4676\n",
      "ratio of state 1 on this device: 0.468\n"
     ]
    }
   ],
   "source": [
    "# Checking that data is balanced over devices.\n",
    "print(\"Diplaying the ratio between state 1 and state -1.\")\n",
    "print(\"If data is iid, the ratio should be close to 0.5\")\n",
    "for y in Y:\n",
    "    print(\"ratio of state 1 on this device: {0}\".format(abs((y == 1).sum().item() / abs(y).sum().item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cost models which will be used to computed cost/loss, gradients, L ...\n",
    "cost_models = build_several_cost_model(LogisticModel, X, Y, nb_devices_for_the_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   it    |   obj   \n",
      "     100 | 6.9314e-01\n",
      "     200 | 6.9314e-01\n",
      "     300 | 6.9314e-01\n",
      "     400 | 6.9314e-01\n",
      "Lips time: 0.7055132389068604\n",
      "Cost time: 0.25673699378967285\n",
      "Grad time: 0\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 0.2588202953338623\n",
      "Grad time: 0\n",
      "== Inside time 0.00010704994201660156\n",
      "== Averaging time : 0.0005185604095458984\n",
      "== Full time : 0.5685954093933105\n",
      "=== Used memory : 1021.82912 Mbytes\n",
      "Gradient Descent: execution time=0.569 seconds\n",
      "Final loss : 0.69314\n",
      "\n",
      "CPU times: user 1.25 s, sys: 6.76 ms, total: 1.25 s\n",
      "Wall time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gc\n",
    "gc.collect()\n",
    "obj_min_by_N = {}\n",
    "obj_min_by_N_descent = FL_VanillaSGD(Parameters(n_dimensions = dim_notebook, \n",
    "                                                     nb_devices=nb_devices_for_the_run,\n",
    "                                                     nb_epoch=500, \n",
    "                                                     quantization_param=0,\n",
    "                                                     momentum = 0., \n",
    "                                                     verbose=True, \n",
    "                                                     cost_models=cost_models,\n",
    "                                                     stochastic=False,\n",
    "                                                     bidirectional=False\n",
    "                                                    ))\n",
    "#obj_min_by_N_descent.set_data(X,Y)\n",
    "obj_min_by_N_descent.run(cost_models)\n",
    "obj_min_by_N = obj_min_by_N_descent.losses[-1]\n",
    "pickle_saver(obj_min_by_N, \"{0}-iid-obj_min\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/constantin/anaconda3/envs/artemis/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                object  number_of_objects    memory  mem_per_object\n",
      "0                  str             133677  23375654      174.866686\n",
      "11                dict              32879  14391976      437.725478\n",
      "1                 type               5653   5142720      909.732885\n",
      "18                code              35158   5093608      144.877638\n",
      "82                list              28402   3342984      117.702415\n",
      "4                tuple              34734   2636040       75.892209\n",
      "45       numpy.ndarray                 78   1582267    20285.474359\n",
      "229                set               1532    839520      547.989556\n",
      "80             weakref               6960    612480       88.000000\n",
      "78   getset_descriptor               6266    501280       80.000000\n",
      "============================================================\n",
      "                                             object  number_of_objects  \\\n",
      "9299                matplotlib.colors._ColorMapping                  1   \n",
      "17192    pytz.lazy.LazySet.__new__.<locals>.LazySet                  2   \n",
      "45                                    numpy.ndarray                 78   \n",
      "7568            numpy.core._type_aliases.TypeNADict                  1   \n",
      "17189  pytz.lazy.LazyList.__new__.<locals>.LazyList                  2   \n",
      "268                              _io.BufferedReader                  2   \n",
      "1648                                  random.Random                  3   \n",
      "9450                            matplotlib.RcParams                 29   \n",
      "270                              _io.BufferedWriter                  3   \n",
      "7078                               _strptime.TimeRE                  1   \n",
      "\n",
      "        memory  mem_per_object  \n",
      "9299     36992    36992.000000  \n",
      "17192    66016    33008.000000  \n",
      "45     1582267    20285.474359  \n",
      "7568      4728     4728.000000  \n",
      "17189     9264     4632.000000  \n",
      "268       8560     4280.000000  \n",
      "1648      7704     2568.000000  \n",
      "9450     64968     2240.275862  \n",
      "270       6696     2232.000000  \n",
      "7078      1208     1208.000000  \n"
     ]
    }
   ],
   "source": [
    "from src.utils.Utilities import check_memory_usage\n",
    "\n",
    "check_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels equal to 1:  0\n",
      "Failures: 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fa5b06341a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mratio_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mratio_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-fa5b06341a53>\u001b[0m in \u001b[0;36mratio_failure\u001b[0;34m(index, guess)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failures: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     print(\"Percent of labels wrongly predicted to be state \" + str(guess) +\" for worker 0: \" + \n\u001b[0;32m---> 22\u001b[0;31m           str(failure/inf_middle * 100) + \"%\")\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "def ratio_failure(index: int, guess: int = 1):\n",
    "    x = X[index]\n",
    "    y = Y[index]\n",
    "    w = obj_min_by_N_descent.model_params[-1]\n",
    "    mul =  torch.tensor(x.dot(w))\n",
    "    inf_middle = 0\n",
    "    failure = 0\n",
    "    for i in range(len(mul)):\n",
    "        if guess == 1:\n",
    "            if torch.sigmoid(mul[i]) >= 0.5:\n",
    "                if y[i] != guess:\n",
    "                    failure +=1\n",
    "                inf_middle +=1\n",
    "        else:\n",
    "            if torch.sigmoid(mul[i]) < 0.5:\n",
    "                if y[i] != guess:\n",
    "                    failure +=1\n",
    "                inf_middle +=1\n",
    "    print(\"Number of labels equal to \" + str(guess) + \": \", inf_middle)\n",
    "    print(\"Failures: {0}\".format(failure))\n",
    "    print(\"Percent of labels wrongly predicted to be state \" + str(guess) +\" for worker 0: \" + \n",
    "          str(failure/inf_middle * 100) + \"%\")\n",
    "\n",
    "index = 0\n",
    "ratio_failure(index, 1)\n",
    "ratio_failure(index, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "Lips time: 0.7055132389068604\n",
      "Cost time: 20.551859378814697\n",
      "Grad time: 0\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 20.422707319259644\n",
      "Grad time: 0\n",
      "== Inside time 1.448000192642212\n",
      "== Averaging time : 0.0030617713928222656\n",
      "== Full time : 4.411934852600098\n",
      "=== Used memory : 2583.064576 Mbytes\n",
      "* === * Time of one run : 4.466008186340332\n",
      "* === * Size of workers : 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:09<00:36,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lips time: 0.7055132389068604\n",
      "Cost time: 21.99114418029785\n",
      "Grad time: 0\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 21.737714529037476\n",
      "Grad time: 0\n",
      "== Inside time 1.534684658050537\n",
      "== Averaging time : 0.0031299591064453125\n",
      "== Full time : 4.527889251708984\n",
      "=== Used memory : 4262.07232 Mbytes\n",
      "* === * Time of one run : 4.561882257461548\n",
      "* === * Size of workers : 104\n",
      "QSGD\n",
      "Lips time: 0.7055132389068604\n",
      "Cost time: 23.750927448272705\n",
      "Grad time: 1.2335772514343262\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 23.299745082855225\n",
      "Grad time: 1.2833600044250488\n",
      "== Inside time 18.993475437164307\n",
      "== Averaging time : 0.0041887760162353516\n",
      "== Full time : 22.61982536315918\n",
      "=== Used memory : 6084.399104 Mbytes\n",
      "* === * Time of one run : 22.662686109542847\n",
      "* === * Size of workers : 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:56<01:02, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lips time: 0.7055132389068604\n",
      "Cost time: 25.66319513320923\n",
      "Grad time: 2.6243550777435303\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 25.032809495925903\n",
      "Grad time: 2.711245059967041\n",
      "== Inside time 21.000775575637817\n",
      "== Averaging time : 0.0053861141204833984\n",
      "== Full time : 24.998295545578003\n",
      "=== Used memory : 7950.31552 Mbytes\n",
      "* === * Time of one run : 25.047027826309204\n",
      "* === * Size of workers : 104\n",
      "Diana\n",
      "Lips time: 0.7055132389068604\n",
      "Cost time: 27.507596969604492\n",
      "Grad time: 3.9552865028381348\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 26.702539920806885\n",
      "Grad time: 4.077139854431152\n",
      "== Inside time 20.21388006210327\n",
      "== Averaging time : 0.00456690788269043\n",
      "== Full time : 24.05967402458191\n",
      "=== Used memory : 9810.030592 Mbytes\n",
      "* === * Time of one run : 24.104429244995117\n",
      "* === * Size of workers : 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [01:46<00:58, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lips time: 0.7055132389068604\n",
      "Cost time: 29.420109510421753\n",
      "Grad time: 5.325900554656982\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 28.422613382339478\n",
      "Grad time: 5.480698585510254\n",
      "== Inside time 21.034231662750244\n",
      "== Averaging time : 0.004900455474853516\n",
      "== Full time : 25.006105184555054\n",
      "=== Used memory : 11677.212672 Mbytes\n",
      "* === * Time of one run : 25.048439502716064\n",
      "* === * Size of workers : 104\n",
      "BiQSGD\n",
      "Lips time: 0.7055132389068604\n",
      "Cost time: 31.279783725738525\n",
      "Grad time: 6.663127660751343\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 30.097740173339844\n",
      "Grad time: 6.848909616470337\n",
      "== Inside time 23.97263813018799\n",
      "== Averaging time : 0.00421595573425293\n",
      "== Full time : 27.842397451400757\n",
      "=== Used memory : 13643.255808 Mbytes\n",
      "* === * Time of one run : 27.89671754837036\n",
      "* === * Size of workers : 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [02:41<00:37, 37.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lips time: 0.7055132389068604\n",
      "Cost time: 33.13889408111572\n",
      "Grad time: 7.971517562866211\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 31.758519887924194\n",
      "Grad time: 8.198947191238403\n",
      "== Inside time 23.76045060157776\n",
      "== Averaging time : 0.00450444221496582\n",
      "== Full time : 27.606268167495728\n",
      "=== Used memory : 15581.835264 Mbytes\n",
      "* === * Time of one run : 27.65887713432312\n",
      "* === * Size of workers : 104\n",
      "Artemis\n",
      "Lips time: 0.7055132389068604\n",
      "Cost time: 34.961376428604126\n",
      "Grad time: 9.250722646713257\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 33.383704662323\n",
      "Grad time: 9.523228406906128\n",
      "== Inside time 23.67951989173889\n",
      "== Averaging time : 0.0047070980072021484\n",
      "== Full time : 27.450745105743408\n",
      "=== Used memory : 17517.228032 Mbytes\n",
      "* === * Time of one run : 27.503297805786133\n",
      "* === * Size of workers : 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:36<00:00, 43.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lips time: 0.7055132389068604\n",
      "Cost time: 36.74556589126587\n",
      "Grad time: 10.48262906074524\n",
      "Lips time: 0.6803417205810547\n",
      "Cost time: 34.96759748458862\n",
      "Grad time: 10.803924083709717\n",
      "== Inside time 22.968239545822144\n",
      "== Averaging time : 0.004826784133911133\n",
      "== Full time : 26.6485595703125\n",
      "=== Used memory : 19455.660032 Mbytes\n",
      "* === * Time of one run : 26.69069766998291\n",
      "* === * Size of workers : 104\n",
      "CPU times: user 14min 7s, sys: 13.4 s, total: 14min 21s\n",
      "Wall time: 3min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "import gc\n",
    "all_descent = {}\n",
    "for type_params in tqdm(KIND_COMPRESSION):\n",
    "    multiple_sg_descent = multiple_run_descent(type_params, cost_models=cost_models, \n",
    "                                               use_averaging=False, streaming=True, \n",
    "                                               logs_file=\"{0}.txt\".format(filename))\n",
    "    all_descent[type_params.name()] = multiple_sg_descent\n",
    "res = ResultsOfSeveralDescents(all_descent, nb_devices_for_the_run)\n",
    "pickle_saver(res, \"{0}-iid-descent\".format(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_models[0].X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sys\n",
    "import gc\n",
    "all_descent = {}\n",
    "X_number_of_bits = []\n",
    "for type_params in tqdm(KIND_COMPRESSION):\n",
    "    multiple_sg_descent = multiple_run_descent(type_params, cost_models=cost_models, \n",
    "                                               use_averaging=False, streaming=True, logs_file=\"rcv1.txt\")\n",
    "    all_descent[type_params.name()] = multiple_sg_descent\n",
    "    del multiple_sg_descent\n",
    "    gc.collect\n",
    "res = ResultsOfSeveralDescents(all_descent, nb_devices_for_the_run)\n",
    "pickle_saver(res, \"{0}-iid-descent\".format(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.Utilities import check_memory_usage\n",
    "\n",
    "check_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Averaging\n",
    "\n",
    "We don't used averaging as it makes the whole process much, much, much ..., much slower."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "obj = pickle_loader(filename + \"-iid-obj_min\")\n",
    "res = pickle_loader(filename + \"-iid-descent\")\n",
    "\n",
    "plot_error_dist(res.get_loss(obj, averaged=True), res.names, res.nb_devices_for_the_run, \n",
    "                dim_notebook, all_error=res.get_std(obj, averaged=True), x_legend=\"Number of passes on data\\n(Avg, iid)\") \n",
    "plot_error_dist(res.get_loss(obj, averaged=True), res.names, res.nb_devices_for_the_run, dim_notebook, \n",
    "                x_points=res.X_number_of_bits, all_error=res.get_std(obj, averaged=True), \n",
    "                x_legend=\"Communicated bits (Avg, iid)\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obj = pickle_loader(filename + \"-iid-obj_min\")\n",
    "res = pickle_loader(filename + \"-iid-descent\")\n",
    "\n",
    "plot_error_dist(res.get_loss(obj), res.names, res.nb_devices_for_the_run, dim_notebook,\n",
    "                x_legend=\"Number of passes on data (iid)\", all_error=res.get_std(obj)) \n",
    "plot_error_dist(res.get_loss(obj), res.names, res.nb_devices_for_the_run, dim_notebook, \n",
    "                x_points=res.X_number_of_bits, x_legend=\"Communicated bits (iid)\", all_error=res.get_std(obj)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
